{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import random\r\n",
    "\r\n",
    "import torch\r\n",
    "import torchvision\r\n",
    "import torch.nn as nn\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class Base(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Base, self).__init__()\r\n",
    "\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1), # (N, 64, 300, 300)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), # (N, 64, 300, 300)\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # (N, 64, 150, 150)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), #(N, 128, 150, 150)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1), # (N, 128, 150, 150)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # (N, 128, 75, 75)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer3 = nn.Sequential(\r\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # (N, 256, 75, 75)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # (N, 256, 75, 75)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # (N, 256, 75, 75)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True) # (N, 256, 38, 38)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer4 = nn.Sequential(\r\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1), # (N, 512, 38, 38)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # (N, 512, 38, 38)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # (N, 512, 38, 38)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # (N, 512, 19, 19)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer5 = nn.Sequential(\r\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # (N, 512, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # (N, 512, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1), # (N, 512, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1) # (N, 512, 19, 19)\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer6 = nn.Sequential(\r\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6), # (N, 1024, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.layer7 = nn.Sequential(\r\n",
    "            nn.Conv2d(1024, 1024, kernel_size=1), # (N, 1024, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.load_pretrained_params()\r\n",
    "\r\n",
    "    def forward(self, input):\r\n",
    "        #Base\r\n",
    "        out = self.layer1(input)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = self.layer3(out)\r\n",
    "        conv4_3_feat = out\r\n",
    "        \r\n",
    "        out = self.layer4(out)\r\n",
    "        out = self.layer5(out)\r\n",
    "        out = self.layer6(out)\r\n",
    "        out = self.layer7(out)\r\n",
    "        conv7_feat = out\r\n",
    "\r\n",
    "        return conv4_3_feat, conv7_feat \r\n",
    "\r\n",
    "    def load_pretrained_params(self):\r\n",
    "\r\n",
    "        state_dict = self.state_dict()\r\n",
    "        params_keys = list(state_dict.keys())\r\n",
    "\r\n",
    "        vgg = torchvision.models.vgg16(pretrained=True)\r\n",
    "            \r\n",
    "        pretrained_state_dict = vgg.state_dict()\r\n",
    "        pretrained_params_keys = list(pretrained_state_dict.keys())\r\n",
    "\r\n",
    "        for i, key in enumerate(params_keys[:-4]):\r\n",
    "            state_dict[key] = pretrained_state_dict[pretrained_params_keys[i]]\r\n",
    "\r\n",
    "\r\n",
    "        #Convert fc6, fc7 to convolutional layers\r\n",
    "        w_fc6 = pretrained_state_dict['classifier.0.weight'].view(4096, 512, 7, 7)\r\n",
    "        b_fc6 = pretrained_state_dict['classifier.0.bias'] # (4096,)\r\n",
    "\r\n",
    "        w_fc7 = pretrained_state_dict['classifier.3.weight'].view(4096, 4096, 1, 1)\r\n",
    "        b_fc7 = pretrained_state_dict['classifier.3.bias'] #(4096, )\r\n",
    "\r\n",
    "        # Subsample parameters of fc6, fc7\r\n",
    "        w_conv6 = torch.index_select(input=w_fc6, dim=0, index=torch.arange(0, 4096, step=4)) # (1024, 512, 7, 7)\r\n",
    "        w_conv6 = torch.index_select(input=w_conv6, dim=2, index=torch.arange(0, 7, step=3)) # (1024, 512, 3, 7)\r\n",
    "        w_conv6 = torch.index_select(input=w_conv6, dim=3, index=torch.arange(0, 7, step=3)) #(1024, 512, 3, 3)\r\n",
    "        \r\n",
    "        b_conv6 = torch.index_select(input=b_fc6, dim=0, index=torch.arange(0, 4096, step=4)) #(1024,)\r\n",
    "\r\n",
    "\r\n",
    "        w_conv7 = torch.index_select(input=w_fc7, dim=0, index=torch.arange(0, 4096, step=4)) #(1024, 4096, 1, 1)\r\n",
    "        w_conv7 = torch.index_select(input=w_conv7, dim=1, index=torch.arange(0, 4096, step=4)) #(1024, 1024, 1, 1)\r\n",
    "\r\n",
    "        b_conv7 = b_conv6 = torch.index_select(input=b_fc6, dim=0, index=torch.arange(0, 4096, step=4)) #(1024,)\r\n",
    "\r\n",
    "\r\n",
    "        state_dict['layer6.0.weight'] = w_conv6\r\n",
    "        state_dict['layer6.0.bias'] = b_conv6\r\n",
    "        state_dict['layer7.0.weight'] = w_conv7\r\n",
    "        state_dict['layer7.0.bias'] = b_conv7\r\n",
    "\r\n",
    "        self.load_state_dict(state_dict)\r\n",
    "\r\n",
    "        print('Loaded pretrained model VGG to Base.') \r\n",
    "\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class Extras(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(Extras, self).__init__()\r\n",
    "        self.layer8 = nn.Sequential(\r\n",
    "            nn.Conv2d(1024, 256, kernel_size=1, padding=0), #(N, 256, 19, 19)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1, stride=2), # (N, 512, 10, 10)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer9 = nn.Sequential(\r\n",
    "            nn.Conv2d(512, 128, kernel_size=1, padding=0), # (N, 128, 10, 10)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1), # (N, 256, 5, 5)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.layer10 = nn.Sequential(\r\n",
    "            nn.Conv2d(256, 128, kernel_size=1, padding=0), #(N, 128, 5, 5)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=0), # (N, 256, 3, 3)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "        \r\n",
    "        self.layer11 = nn.Sequential(\r\n",
    "            nn.Conv2d(256, 128, kernel_size=1, padding=0), #(N, 128, 3, 3)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=0), #(N, 256, 1, 1)\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "        )\r\n",
    "\r\n",
    "        self.init_params()\r\n",
    "\r\n",
    "    def init_params(self):\r\n",
    "        for c in self.children():\r\n",
    "            if isinstance(c, nn.Conv2d):\r\n",
    "                nn.init.xavier_uniform_(c.weight)\r\n",
    "                nn.init.constant_(c.bias, 0.)\r\n",
    "        \r\n",
    "    def forward(self, input):\r\n",
    "        #Extras\r\n",
    "        out = self.layer8(input)\r\n",
    "        conv8_2_feat = out\r\n",
    "        out = self.layer9(out)\r\n",
    "        conv9_2_feat = out\r\n",
    "        out = self.layer10(out)\r\n",
    "        conv10_2_feat = out\r\n",
    "        conv11_2_feat = self.layer11(out)\r\n",
    "\r\n",
    "        return conv8_2_feat, conv9_2_feat, conv10_2_feat, conv11_2_feat\r\n",
    "        \r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Predict(nn.Module):\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        super(Predict, self).__init__()\r\n",
    "        self.num_classes = num_classes\r\n",
    "        num_boxes = {'conv4_3':4, 'conv7':6, 'conv8_2':6, 'conv9_2':6, 'conv10_2':4, 'conv11_2':4} #Number of default boxes for each feature\r\n",
    "\r\n",
    "        #Location\r\n",
    "        self.loc_conv4_3 = nn.Conv2d(256, num_boxes['conv4_3']*4, kernel_size=3, padding=1)\r\n",
    "        self.loc_conv7 = nn.Conv2d(1024, num_boxes['conv7']*4, kernel_size=3, padding=1)\r\n",
    "        self.loc_conv8_2 = nn.Conv2d(512, num_boxes['conv8_2']*4, kernel_size=3, padding=1)\r\n",
    "        self.loc_conv9_2 = nn.Conv2d(256, num_boxes['conv9_2']*4, kernel_size=3, padding=1)\r\n",
    "        self.loc_conv10_2 = nn.Conv2d(256, num_boxes['conv10_2']*4, kernel_size=3, padding=1)\r\n",
    "        self.loc_conv11_2 = nn.Conv2d(256, num_boxes['conv11_2']*4, kernel_size=3, padding=1)\r\n",
    "\r\n",
    "        #Classify\r\n",
    "        self.cl_conv4_3 = nn.Conv2d(256, num_boxes['conv4_3']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "        self.cl_conv7 = nn.Conv2d(1024, num_boxes['conv7']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "        self.cl_conv8_2 = nn.Conv2d(512, num_boxes['conv8_2']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "        self.cl_conv9_2 = nn.Conv2d(256, num_boxes['conv9_2']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "        self.cl_conv10_2 = nn.Conv2d(256, num_boxes['conv10_2']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "        self.cl_conv11_2 = nn.Conv2d(256, num_boxes['conv11_2']*self.num_classes, kernel_size=3, padding=1)\r\n",
    "\r\n",
    "        self.init_params()\r\n",
    "\r\n",
    "    def init_params(self):\r\n",
    "        for c in self.children():\r\n",
    "            if isinstance(c, nn.Conv2d):\r\n",
    "                nn.init.xavier_uniform_(c.weight)\r\n",
    "                nn.init.constant_(c.bias, 0.)\r\n",
    "    \r\n",
    "    \r\n",
    "    '''If you just want to reshape tensors, use torch.reshape.\r\n",
    "       If you're also concerned about memory usage and want to ensure that the two tensors share the same data, use torch.view.'''\r\n",
    "       \r\n",
    "    def forward(self, conv4_3_feat, conv7_feat, conv8_2_feat, conv9_2_feat, conv10_2_feat, conv11_2_feat):\r\n",
    "        batch_size = conv4_3_feat.shape[0]\r\n",
    "\r\n",
    "        #Location\r\n",
    "        loc_conv4_3 = self.loc_conv4_3(conv4_3_feat) # (N, 16, 38, 38)\r\n",
    "        loc_conv4_3 = loc_conv4_3.permute(0, 2, 3, 1).contiguous() # (N, 38, 38, 16)\r\n",
    "        loc_conv4_3 = loc_conv4_3.view(batch_size, -1, 4) #(N, 5776, 4)\r\n",
    "        \r\n",
    "        loc_conv7 = self.loc_conv7(conv7_feat) #(N, 24, 19, 19)\r\n",
    "        loc_conv7 = loc_conv7.permute(0, 2, 3, 1).contiguous() #(N, 19, 19, 24)\r\n",
    "        loc_conv7 = loc_conv7.view(batch_size, -1, 4) #(N, 2166, 4)\r\n",
    "\r\n",
    "        loc_conv8_2 = self.loc_conv8_2(conv8_2_feat)\r\n",
    "        loc_conv8_2 = loc_conv8_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        loc_conv8_2 = loc_conv8_2.view(batch_size, -1, 4)\r\n",
    "        \r\n",
    "        loc_conv9_2 = self.loc_conv9_2(conv9_2_feat)\r\n",
    "        loc_conv9_2 = loc_conv9_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        loc_conv9_2 = loc_conv9_2.view(batch_size, -1, 4)\r\n",
    "\r\n",
    "        loc_conv10_2 = self.loc_conv10_2(conv10_2_feat)\r\n",
    "        loc_conv10_2 = loc_conv10_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        loc_conv10_2 = loc_conv10_2.view(batch_size, -1, 4)\r\n",
    "\r\n",
    "        loc_conv11_2 = self.loc_conv11_2(conv11_2_feat)\r\n",
    "        loc_conv11_2 = loc_conv11_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        loc_conv11_2 = loc_conv11_2.view(batch_size, -1, 4)\r\n",
    "\r\n",
    "        #Classification\r\n",
    "        cl_conv4_3 = self.cl_conv4_3(conv4_3_feat)  #(N, classes*4, 38, 38)\r\n",
    "        cl_conv4_3 = cl_conv4_3.permute(0, 2, 3, 1).contiguous() #(N, 38, 38, classes*4)\r\n",
    "        cl_conv4_3 = cl_conv4_3.view(batch_size, -1, self.num_classes) # (N, 5776, classes)\r\n",
    "\r\n",
    "        cl_conv7 = self.cl_conv7(conv7_feat) #(N, classes*6, 19, 19)\r\n",
    "        cl_conv7 = cl_conv7.permute(0, 2, 3, 1).contiguous() # (N, 19, 19, classes*6)\r\n",
    "        cl_conv7 = cl_conv7.view(batch_size, -1, self.num_classes) # (N, 2166, classes)\r\n",
    "\r\n",
    "        cl_conv8_2 = self.cl_conv8_2(conv8_2_feat)\r\n",
    "        cl_conv8_2 = cl_conv8_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        cl_conv8_2 = cl_conv8_2.view(batch_size, -1, self.num_classes)\r\n",
    "\r\n",
    "        cl_conv9_2 = self.cl_conv9_2(conv9_2_feat)\r\n",
    "        cl_conv9_2 = cl_conv9_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        cl_conv9_2 = cl_conv9_2.view(batch_size, -1, self.num_classes)\r\n",
    "\r\n",
    "        cl_conv10_2 = self.cl_conv10_2(conv10_2_feat)\r\n",
    "        cl_conv10_2 = cl_conv10_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        cl_conv10_2 = cl_conv10_2.view(batch_size, -1, self.num_classes)\r\n",
    "\r\n",
    "        cl_conv11_2 = self.cl_conv11_2(conv11_2_feat)\r\n",
    "        cl_conv11_2 = cl_conv11_2.permute(0, 2, 3, 1).contiguous()\r\n",
    "        cl_conv11_2 = cl_conv11_2.view(batch_size, -1, self.num_classes)\r\n",
    "\r\n",
    "        \r\n",
    "        locs = torch.cat((loc_conv4_3, loc_conv7, loc_conv8_2, loc_conv9_2, loc_conv10_2, loc_conv11_2), dim=1) # dim: the dimention over which the tensors are concatnated\r\n",
    "        classifs = torch.cat((cl_conv4_3, cl_conv7, cl_conv8_2, cl_conv9_2, cl_conv10_2, cl_conv11_2), dim=1) \r\n",
    "\r\n",
    "        return locs, classifs\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class DefaultBoxes():\r\n",
    "    def __init__(self, aspect_ratios, features_size):\r\n",
    "        self.ratios = aspect_ratios #for each feature\r\n",
    "        self.feat_size = feature_size\r\n",
    "\r\n",
    "    def create_dbox(self, m=6, s_max=0.9, s_min=0.2):\r\n",
    "        \"\"\" Args:\r\n",
    "                m: number of feature maps for prediction,\r\n",
    "                s_max: max scale for each default bounding box,\r\n",
    "                s_min: min scale for each default bounding box,  \r\n",
    "\r\n",
    "            Return: Tensor of default bounding boxes with (cx, cy, w, h)     \r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        def_boxes = []\r\n",
    "\r\n",
    "        for k in range(m):\r\n",
    "            s_k = s_min + (s_max - s_min) * k / (m - 1)\r\n",
    "            w = []\r\n",
    "            h = []\r\n",
    "            for r in self.ratios[k]:\r\n",
    "                sqrt_r = np.sqrt(r)\r\n",
    "\r\n",
    "                temp_w = s_k * sqrt_r\r\n",
    "                temp_h = s_k / sqrt_r\r\n",
    "                w.append(temp_w)\r\n",
    "                h.append(temp_h)\r\n",
    "                if r == 1:\r\n",
    "                    temp_w = np.sqrt(s_k**2 + 1) * sqrt_r\r\n",
    "                    temp_h = np.sqrt(s_k**2 + 1) * sqrt_r\r\n",
    "                    w.append(temp_w)\r\n",
    "                    h.append(temp_h)\r\n",
    "\r\n",
    "            for i in range(1, self.feat_size[k] + 1):\r\n",
    "                cy = (i + 0.5) / self.feat_size[k]\r\n",
    "\r\n",
    "                for j in range(1, self.feat_size[k] + 1):\r\n",
    "                    cx = (j + 0.5) / self.feat_size[k]\r\n",
    "                    \r\n",
    "                    for l in range(len(w)):\r\n",
    "                        temp = [cx, cy, w[l], h[l]]\r\n",
    "                        def_boxes.append(temp)\r\n",
    "                        \r\n",
    "        def_boxes = torch.tensor(def_boxes)\r\n",
    "        def_boxes.clamp_(min=0, max=1)\r\n",
    "        return def_boxes\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class SSD300(nn.Module):\r\n",
    "    def __init__(self, num_classes, aspect_ratios, features_size):\r\n",
    "        super(SSD300, self).__init__()\r\n",
    "\r\n",
    "        self.num_classes = num_classes\r\n",
    "\r\n",
    "        self.base = Base()\r\n",
    "        self.extras = Extras()\r\n",
    "        self.predict = Predict(num_classes)\r\n",
    "\r\n",
    "        dbox = DefaultBoxes(aspect_ratios, features_size)\r\n",
    "        self.def_boxes = dbox.create_dbox()\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, image):\r\n",
    "        conv4_3_feat, conv7_feat = self.base(image) #(N, 512, 38, 38), (N, 1024, 19, 19)\r\n",
    "\r\n",
    "        # L2 Norm \r\n",
    "        norm = conv4_3_feat.pow(2).sum(dim=1, keepdim=True) #(N, 1, 38, 38)\r\n",
    "        norm = torch.sqrt(norm)\r\n",
    "        conv4_3_feat = conv4_3_feat / norm #(N, 1, 38, 38)\r\n",
    "        conv4_3_feat = conv4_3_feat * 20 \r\n",
    "\r\n",
    "\r\n",
    "        conv8_2_feat, conv9_2_feat, conv10_2_feat, conv11_2_feat = self.extras(conv7_feat)\r\n",
    "        locs, classifs = self.predict(conv4_3_feat, conv7_feat, conv8_2_feat, conv9_2_feat, conv10_2_feat, conv11_2_feat)\r\n",
    "\r\n",
    "        return locs, classifs\r\n",
    "    \r\n",
    "\r\n",
    "      "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def NMS(boxes, scores, overlap=0.45, top_k=200):\r\n",
    "    \"\"\" boxes: (8732, 4)\r\n",
    "        scores: (8732, )\r\n",
    "        Giu 200 box co score cao nhat\r\n",
    "        Cac box co overlap > 0.45 so voi box co score cao nhat se bi loai\r\n",
    "\r\n",
    "        Return: tensor chua index của các box thỏa mãn\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    count = 0\r\n",
    "    keep = []\r\n",
    "    \r\n",
    "    xmin = boxes[:, 0] # (8732, )\r\n",
    "    ymin = boxes[:, 1]\r\n",
    "    xmax = boxes[:, 2]\r\n",
    "    ymax = boxes[:, 3]\r\n",
    "\r\n",
    "    area = (xmax - xmin) * (ymax - ymin)\r\n",
    "\r\n",
    "    _, idx = torch.sort(scores, dim=0)\r\n",
    "\r\n",
    "    idx = idx[-top_k:]\r\n",
    "    \r\n",
    "\r\n",
    "    while(idx.numel() > 0):\r\n",
    "\r\n",
    "        i = idx[-1] #Lấy index của box có score cao nhất\r\n",
    "        keep.append(i)\r\n",
    "\r\n",
    "        if idx.size(0) == 1:\r\n",
    "            break\r\n",
    "\r\n",
    "        idx = idx[:-1]\r\n",
    "\r\n",
    "        temp_xmin = torch.index_select(input=xmin, dim=0, index=idx) # (199,)\r\n",
    "        temp_ymin = torch.index_select(input=ymin, dim=0, index=idx)\r\n",
    "        temp_xmax = torch.index_select(input=xmax, dim=0, index=idx)\r\n",
    "        temp_ymax = torch.index_select(input=ymax, dim=0, index=idx)\r\n",
    "\r\n",
    "        temp_xmin.clamp_(min=xmin[i]) #(199, )\r\n",
    "        temp_ymin.clamp_(min=ymin[i])\r\n",
    "        temp_xmax.clamp_(max=xmax[i])\r\n",
    "        temp_ymax.clamp_(max=ymax[i])\r\n",
    "        \r\n",
    "        temp_w = temp_xmax - temp_xmin #(199, )\r\n",
    "        temp_h = temp_ymax - temp_ymin\r\n",
    "\r\n",
    "        temp_w.clamp_(min=0.) # (199, )\r\n",
    "        temp_h.clamp_(min=0.)\r\n",
    "\r\n",
    "        intersect = temp_w * temp_h  #(199, )\r\n",
    "        others_area = torch.index_select(input=area, dim=0, index=idx) # (199, )\r\n",
    "\r\n",
    "        union = area[i] + others_area - 2 * intersect\r\n",
    "\r\n",
    "        iou = intersect / union \r\n",
    "\r\n",
    "        idx = idx[torch.le(iou, overlap)]\r\n",
    "\r\n",
    "    return torch.tensor(keep)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "boxes = np.random.randint(1, 300, (8732,4))\r\n",
    "boxes = torch.from_numpy(boxes)\r\n",
    "\r\n",
    "scores = torch.rand(8732)\r\n",
    "\r\n",
    "keep = NMS(boxes, scores)\r\n",
    "\r\n",
    "keep.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([187])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "x = torch.rand((1, 3, 300, 300 ))\r\n",
    "aspect_ratios = [[1, 2, 0.5], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 0.5], [1, 2, 0.5]]\r\n",
    "feature_size = [38, 19, 10, 5, 3, 1]\r\n",
    "\r\n",
    "model = SSD300(21, aspect_ratios, feature_size)\r\n",
    "\r\n",
    "locs, classifs = model(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded pretrained model VGG to Base.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "classifs.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 8732, 21])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\r\n",
    "print(sum(p.numel() for p in model.parameters()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "26054574\n",
      "26054574\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "w = torch.empty(3, 5)\r\n",
    "nn.init.uniform_(w, a=1, b=2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.9320, 1.5141, 1.3847, 1.5824, 1.8143],\n",
       "        [1.9848, 1.9508, 1.9867, 1.4063, 1.8686],\n",
       "        [1.8464, 1.7952, 1.2754, 1.9279, 1.8279]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "aspect_ratios = [[1, 2, 0.5], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 0.5], [1, 2, 0.5]]\r\n",
    "feature_size = [38, 19, 10, 5, 3, 1]\r\n",
    "\r\n",
    "\r\n",
    "defbox = DefaultBoxes(aspect_ratios, feature_size)\r\n",
    "\r\n",
    "defbox_tensor = defbox.create_dbox()\r\n",
    "\r\n",
    "df = pd.DataFrame(defbox_tensor.numpy())\r\n",
    "\r\n",
    "df.head(15)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.039474  0.039474  0.200000  0.200000\n",
       "1   0.039474  0.039474  1.000000  1.000000\n",
       "2   0.039474  0.039474  0.282843  0.141421\n",
       "3   0.039474  0.039474  0.141421  0.282843\n",
       "4   0.065789  0.039474  0.200000  0.200000\n",
       "5   0.065789  0.039474  1.000000  1.000000\n",
       "6   0.065789  0.039474  0.282843  0.141421\n",
       "7   0.065789  0.039474  0.141421  0.282843\n",
       "8   0.092105  0.039474  0.200000  0.200000\n",
       "9   0.092105  0.039474  1.000000  1.000000\n",
       "10  0.092105  0.039474  0.282843  0.141421\n",
       "11  0.092105  0.039474  0.141421  0.282843\n",
       "12  0.118421  0.039474  0.200000  0.200000\n",
       "13  0.118421  0.039474  1.000000  1.000000\n",
       "14  0.118421  0.039474  0.282843  0.141421"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.282843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.282843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.282843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "ratios = [[1, 2, 0.5], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 3, 0.5, 0.333], [1, 2, 0.5], [1, 2, 0.5]]\r\n",
    "feat_size = [38, 19, 10, 5, 3, 1]\r\n",
    "\r\n",
    "def_box = []\r\n",
    "m = 6\r\n",
    "s_max = 0.9\r\n",
    "s_min = 0.2\r\n",
    "for k in range(m):\r\n",
    "    s_k = s_min + (s_max - s_min) * k / (m - 1)\r\n",
    "    w = []\r\n",
    "    h = []\r\n",
    "    for r in ratios[k]:\r\n",
    "        sqrt_r = np.sqrt(r)\r\n",
    "\r\n",
    "        temp_w = s_k * sqrt_r\r\n",
    "        temp_h = s_k / sqrt_r\r\n",
    "        w.append(temp_w)\r\n",
    "        h.append(temp_h)\r\n",
    "        if r == 1:\r\n",
    "            temp_w = np.sqrt(s_k**2+1) * sqrt_r\r\n",
    "            temp_h = np.sqrt(s_k**2+1) * sqrt_r\r\n",
    "            w.append(temp_w)\r\n",
    "            h.append(temp_h)\r\n",
    "    print('w = ', w)\r\n",
    "    print('h = ', h)\r\n",
    "\r\n",
    "    for i in range(1, feat_size[k]+1):\r\n",
    "        cy = (i + 0.5) / feat_size[k]\r\n",
    "        for j in range(1, feat_size[k]+1):\r\n",
    "            cx = (j + 0.5) / feat_size[k]\r\n",
    "            for l in range(len(w)):\r\n",
    "                temp = [cx, cy, w[l], h[l]]\r\n",
    "                def_box.append(temp)\r\n",
    "                # print(temp)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w =  [0.2, 1.019803902718557, 0.28284271247461906, 0.14142135623730953]\n",
      "h =  [0.2, 1.019803902718557, 0.1414213562373095, 0.282842712474619]\n",
      "w =  [0.33999999999999997, 1.0562196741208714, 0.4808326112068523, 0.5888972745734182, 0.24041630560342614, 0.19620091742904772]\n",
      "h =  [0.33999999999999997, 1.0562196741208714, 0.2404163056034261, 0.19629909152447275, 0.4808326112068522, 0.5891919442313744]\n",
      "w =  [0.48, 1.1092339699089637, 0.6788225099390857, 0.831384387633061, 0.33941125496954283, 0.27698953048806735]\n",
      "h =  [0.48, 1.1092339699089637, 0.3394112549695428, 0.27712812921102037, 0.6788225099390855, 0.831800391856058]\n",
      "w =  [0.6199999999999999, 1.176605286406618, 0.8768124086713188, 1.0738715006927038, 0.4384062043356594, 0.357778143547087]\n",
      "h =  [0.6199999999999999, 1.176605286406618, 0.43840620433565936, 0.3579571668975679, 0.8768124086713187, 1.0744088394807416]\n",
      "w =  [0.76, 1.2560254774486066, 1.0748023074035524, 0.5374011537017762]\n",
      "h =  [0.76, 1.2560254774486066, 0.5374011537017761, 1.0748023074035522]\n",
      "w =  [0.8999999999999999, 1.345362404707371, 1.2727922061357855, 0.6363961030678927]\n",
      "h =  [0.8999999999999999, 1.345362404707371, 0.6363961030678926, 1.2727922061357853]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def_box = torch.tensor(def_box)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def_box.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([8732, 4])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "26054574"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "x = torch.rand(2, 3, 4)\r\n",
    "x = x.permute(1, 2, 0)\r\n",
    "x = x.reshape(3, 2, -1)\r\n",
    "\r\n",
    "print(x)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[0.8940, 0.3919, 0.2239, 0.0717],\n",
      "         [0.7577, 0.1557, 0.2804, 0.1712]],\n",
      "\n",
      "        [[0.5233, 0.2915, 0.5151, 0.6187],\n",
      "         [0.1340, 0.7744, 0.2067, 0.6920]],\n",
      "\n",
      "        [[0.0206, 0.8929, 0.2861, 0.9731],\n",
      "         [0.7506, 0.6531, 0.0704, 0.1942]]])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "x[0, 0] = 1\r\n",
    "x"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [0.7577, 0.1557, 0.2804, 0.1712]],\n",
       "\n",
       "        [[0.5233, 0.2915, 0.5151, 0.6187],\n",
       "         [0.1340, 0.7744, 0.2067, 0.6920]],\n",
       "\n",
       "        [[0.0206, 0.8929, 0.2861, 0.9731],\n",
       "         [0.7506, 0.6531, 0.0704, 0.1942]]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgg = torchvision.models.vgg16(pretrained=True)\r\n",
    "\r\n",
    "print(vgg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "state_dict = vgg.state_dict()\r\n",
    "p_fc6 = state_dict['classifier.0.weight'].view(4096, 512, 7, 7)\r\n",
    "index = torch.tensor([0, 1, 2])\r\n",
    "p_conv6 = torch.index_select(input=p_fc6, dim=2, index=index)\r\n",
    "print(p_conv6.shape)\r\n",
    "p_conv6 = torch.index_select(input=p_conv6, dim=3, index=index)\r\n",
    "\r\n",
    "print(p_conv6.shape)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([4096, 512, 3, 7])\n",
      "torch.Size([4096, 512, 3, 3])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p_fc7 = state_dict['classifier.3.weight'].view(4096, 4096, 1, 1)\r\n",
    "index = torch.tensor([0, 1, 2])\r\n",
    "p_conv7 = torch.index_select(input=p_fc7, dim=0, index=index)\r\n",
    "print(p_conv7.shape)\r\n",
    "p_conv7 = torch.index_select(input=p_conv7, dim=1, index=index)\r\n",
    "print(p_conv7.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 4096, 1, 1])\n",
      "torch.Size([3, 3, 1, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ssd.state_dict()['base.layer6.0.weight'].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1024, 512, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vgg = torchvision.models.vgg16(pretrained=True)\r\n",
    "for param in vgg.parameters():\r\n",
    "    param.requires_grad = False\r\n",
    "            \r\n",
    "pretrained_state_dict = vgg.state_dict()\r\n",
    "pretrained_params_keys = list(pretrained_state_dict.keys())\r\n",
    "\r\n",
    "\r\n",
    "        #Convert fc6, fc7 to convolutional layers\r\n",
    "w_fc6 = pretrained_state_dict['classifier.0.weight'].view(4096, 512, 7, 7)\r\n",
    "b_fc6 = pretrained_state_dict['classifier.0.bias'] # (4096,)\r\n",
    "\r\n",
    "w_fc7 = pretrained_state_dict['classifier.3.weight'].view(4096, 4096, 1, 1)\r\n",
    "b_fc7 = pretrained_state_dict['classifier.3.bias'] #(4096, )\r\n",
    "\r\n",
    "        # Subsample parameters of fc6, fc7\r\n",
    "w_conv6 = torch.index_select(input=w_fc6, dim=0, index=torch.arange(0, 4096, step=4)) # (1024, 512, 7, 7)\r\n",
    "w_conv6 = torch.index_select(input=w_conv6, dim=2, index=torch.arange(0, 7, step=3)) # (1024, 512, 3, 7)\r\n",
    "w_conv6 = torch.index_select(input=w_conv6, dim=3, index=torch.arange(0, 7, step=3)) #(1024, 512, 3, 3)\r\n",
    "b_conv6 = torch.index_select(input=b_fc6, dim=0, index=torch.arange(0, 4096, step=4)) #(1024,)\r\n",
    "\r\n",
    "\r\n",
    "w_conv7 = torch.index_select(input=w_fc7, dim=0, index=torch.arange(0, 4096, step=4)) #(1024, 4096, 1, 1)\r\n",
    "w_conv7 = torch.index_select(input=w_conv7, dim=1, index=torch.arange(0, 4096, step=4)) #(1024, 1024, 1, 1)\r\n",
    "b_conv7 = b_conv6 = torch.index_select(input=b_fc6, dim=0, index=torch.arange(0, 4096, step=4)) #(1024,)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "w_conv7.requires_grad"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('torch': conda)"
  },
  "interpreter": {
   "hash": "bda2dbd333357889da984cf9be9c50cb5e8115445fa270a04925ab0de91782a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}